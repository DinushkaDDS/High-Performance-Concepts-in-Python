{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Matrix and Vector operations/calculations**\r\n",
    "\r\n",
    "Matrix/Vector operations are extremely important topic in high performance computing, because many of the large calculations are related to that. Also in fields like ML/ Data science, Image processing, Computer Graphics etc. Matrices are extremely important due to their properties.\r\n",
    "\r\n",
    "In this note book first we will define a sample such problem as running example and use it to explore techniques related to Matrix/Vector operations.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running Problem:- Diffusion of fluids (example for diffusion is dye in water).\r\n",
    "\r\n",
    "The one dimensional partial differential equation of diffusion is as follows.\r\n",
    "\r\n",
    "<center><image src=\"./img/5.jpg\" width=\"250\"/></center>\r\n",
    "\r\n",
    "Here, `u` is the vector representing the quatities we are diffusing. For example this could represent the dye value in the location of the fluid space. In general, this will be a 2D or 3D matrix representing an actual area or volume of fluid. `D` is a value that represents the properties of the fuild we are considering. `x`, `t` represent the direction and time respectively.\r\n",
    "\r\n",
    "Since we cant directly calculate the continuous values, we approximate above equation as follows using Eulars method.(Basically we use the differenciation limit formula for the approximation.)\r\n",
    "\r\n",
    "<center><image src=\"./img/6.jpg\" width=\"500\"/></center>\r\n",
    "\r\n",
    "Above `dt` represents the framerate(minimum time frame), `dx` represents the resolution of the image ie: smaller the dx smaller a region the matrix u cell represents. Generally we consider dx to be 1.\r\n",
    "\r\n",
    "The basic psuedo code implementation of above for 1D (one dimension) is as follows.\r\n",
    "\r\n",
    "\r\n",
    "<pre style=\"color:yellow\">\r\n",
    "\r\n",
    "# Initializing the data and conditions\r\n",
    "u = space vector of size N\r\n",
    "for i in range(N):\r\n",
    "    u[i] = 0 if water else 1 #(if theres dye)\r\n",
    "\r\n",
    "D = 1\r\n",
    "dx = 1\r\n",
    "t = 0\r\n",
    "dt = 0.0001\r\n",
    "\r\n",
    "while(True):\r\n",
    "\r\n",
    "    print(f'time: {t}')\r\n",
    "\r\n",
    "    u_next = vector of size N\r\n",
    "    for i in range(N):\r\n",
    "        u_next[i] = u[i] + D * dt * (u[(i+1)%N] + u[(i-1)%N] - 2 * u[i])\r\n",
    "\r\n",
    "\r\n",
    "    u = u_next\r\n",
    "    t = t + dt\r\n",
    "    visualize(u)\r\n",
    "\r\n",
    "</pre>\r\n",
    "\r\n",
    "In above code all the parts which include `%N` are to solve the problem of out of bound values in the vector space. (ie: [0 - dx] or [N + dx] can be out of bound). Rather than doing that we can simply make them zero or use the same value as the closest value( same as convolutional neural networks case.)\r\n",
    "\r\n",
    "Depending on the dimensions we need to consider, it is required to update the code. For example for 2D space diffision, we have 2 directions to consider for the diffusion gradient.\r\n",
    "\r\n",
    "Below is an actual implementation of the diffusion algorithm for 2D space.\r\n",
    "<center><image src=\"./img/7.jpg\" width=\"400\"/></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below will act as the initialization of data and executor for the diffusion equation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "%%writefile scripts/run_experiment.py\r\n",
    "\r\n",
    "import time\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, dt, D = 1.0):\r\n",
    "\r\n",
    "    max_y, max_x = len(grid), len(grid[0])\r\n",
    "\r\n",
    "    grid_next = [[0.0]*max_x]*max_y\r\n",
    "\r\n",
    "    for i in range(max_y):\r\n",
    "        for j in range(max_x):\r\n",
    "            \r\n",
    "            y_dir_gradient2 = (grid[(i + 1) % max_y][j] + grid[(i - 1) % \\\r\n",
    "                                                    max_y][j] - 2 * grid[i][j]) \r\n",
    "            x_dir_gradient2 = (grid[i][(j + 1) % max_x] + grid[i][(j - 1) % \\\r\n",
    "                                                     max_x] - 2 * grid[i][j])\r\n",
    "\r\n",
    "            grid_next[i][j] = grid[i][j] + D * dt * (x_dir_gradient2 + y_dir_gradient2)\r\n",
    "\r\n",
    "    return grid_next\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "\r\n",
    "    grid = [[0.0]*max_x]*max_y\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    for i in range(block_low, block_high):\r\n",
    "        for j in range(block_low, block_high):\r\n",
    "            grid[i][j] = 0.005\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        grid = step(grid, 0.1)\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640, 640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/run_experiment.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The line profling output for the above code segment is as follows.\r\n",
    "\r\n",
    "<center><image src=\"./img/8.jpg\" width=\"800\"/></center>\r\n",
    "\r\n",
    "As we can see, creation of new_grid in each step function call takes a huge amount of time per hit. This is in fact unnecessary as the dimensions of the grid does not change with time, which means we can essentially declare the list once and use it throughout all the steps. So more optimized code would be like below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "%%writefile scripts/run_experiment_segmented.py\r\n",
    "\r\n",
    "import time\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, dt, grid_next, D = 1.0):\r\n",
    "\r\n",
    "    max_y, max_x = len(grid), len(grid[0])\r\n",
    "\r\n",
    "    for i in range(max_y):\r\n",
    "        for j in range(max_x):\r\n",
    "            \r\n",
    "            y_dir_gradient2 = (grid[(i + 1) % max_y][j] + grid[(i - 1) % \\\r\n",
    "                                                    max_y][j] - 2 * grid[i][j]) \r\n",
    "            x_dir_gradient2 = (grid[i][(j + 1) % max_x] + grid[i][(j - 1) % \\\r\n",
    "                                                     max_x] - 2 * grid[i][j])\r\n",
    "\r\n",
    "            grid_next[i][j] = grid[i][j] + D * dt * (x_dir_gradient2 + y_dir_gradient2)\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "\r\n",
    "    grid = [[0.0]*max_x]*max_y\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    for i in range(block_low, block_high):\r\n",
    "        for j in range(block_low, block_high):\r\n",
    "            grid[i][j] = 0.005\r\n",
    "\r\n",
    "\r\n",
    "    # Predefining the next grid\r\n",
    "    grid_next = [[0.0]*max_x]*max_y\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        step(grid, 0.1, grid_next)\r\n",
    "\r\n",
    "        # Swapping the variables because values inside grid does not matter for next iteration\r\n",
    "        grid, grid_next = grid_next, grid\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640, 640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/run_experiment_segmented.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<center><image src=\"./img/9.jpg\" width=\"800\"/></center>\r\n",
    "\r\n",
    "We can see that the execution time has been reduced by about 20% just by separating the time consuming one time operations. But still we can see that, most of the operations we do in here is very similar. So doing this in vectorized fashion makes more sense. But python does not support vectorization natively and therefore cannot recognize whether it is possible to optimize a code segment.\r\n",
    "\r\n",
    "\r\n",
    "In python data in lists are stores as pointers. Which means original data will be in some place in memory while the list stores it's address. This is generally great for many use cases. But not for Matrix/ Vector based situations. For example consider the `data[x][y]` list item. Since we are accesing using pointers, python need to do 2 memory lookups just to locate one item. This is generally fine. But for many such operations it can be costly. \r\n",
    "\r\n",
    "Also in most cases other nearby items needed for calculations as well. Therefore as an optimaization we can take that block of memory in one operation rather than locating indivudual item (caching). But if the data is fragmented in the memory this cannot be done and therefore CPU need to wait for the data to come (cache misses).\r\n",
    "\r\n",
    "To avoid above cache missing problem, modern CPUs have few mechanisms namely `branch prediction` and `pipelining`, which try to predict the next instruction and load the relevant data before hand to improve the CPU performance. But still the most effective way of solving the mentioned problem is allocating the memory in a proper way.\r\n",
    "\r\n",
    "In performance analysis, we can identify the how the data is getting moved to the CPU using various tools.\r\n",
    "- Linux --> `perf` tool\r\n",
    "- OSX   --> google's `gperftools` or provided `Instruments` tool\r\n",
    "- Windows --> `Visual Studio Profiler `\r\n",
    "\r\n",
    "\r\n",
    "**Important concepts to note:-**\r\n",
    "\r\n",
    "* Difference between number of CPU instructions and CPU cycles indicate how well our code is vectorized and pipelined.\r\n",
    "* CS (Context Switches) and migrations indicates how many times our program halted to let other applications run (may be due to I/O operations, waiting operations etc.). We cant control this happening, but can reduce the occurance by reducing blocking operations. (btw migrations means the CPU core which execute the program halt it and start the rest of the program in another core to make all cores evenly used.)\r\n",
    "* Page faults occur when the requested memory is not available. Then kernal allocate/ read the memory to the cache. This is called `minor page fault` and problamatic in CPU bound situations. On the other hand `hard page faults` means required data is not available even in the memory, so need to read it from disk which obviously problematic in any program in general.\r\n",
    "* It is important to lay the data in memory to reduce `cache-misses`.\r\n",
    "* Branches in CPU optimization context is a point where the execution of the code flow change. For example if-else conditions, function calls can be considered as branches. Modern CPUs try to predict the flow before hand and load the instructions early. This can lead to more performance if prediction is correct. If they are wrong execution may take longer. This is called `branch miss`. For example some loops may run faster on sorted loops than non sorted one.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With those in mind, we can see that higher number of instructions executed for a single CPU cycle improve performance of our program. to achieve that we can make sure all the related data need for the future processing as well is pre-loaded to the cache. But since python lists store data as pointers, actual data may not in same memory block(fragmented) which can be copied to the cache. To avoid this issue, we can use python `array` module instead of lists.\r\n",
    "\r\n",
    "Python arrays store data sequentially in the memory rather than pointers. So now kernal can load continuous memory chunks to the cache, which in turn reduce cache misses. But this does not vectorize the process we require. In order to perform vectorized CPU operations we need to use special modules which instructs python to use them.\r\n",
    "\r\n",
    "> Due to the nature of implementation of python `array` it is slower than normal lists when creating. Not only that, it has an overhead when reading values as well. Therefore generally not good for math operations. But for storing fixed type data.\r\n",
    "\r\n",
    "So to deal with above problems, python has a package `numpy` which stores data as contiguous chunks of memory and support vectorized operations. Below examples show the improvements of numpy compared to normal lists on vectorizable operations.\r\n",
    "\r\n",
    "Consider taking a sum of square of list values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from array import array\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def sum_square_lists(vector):\r\n",
    "    sum_val = 0\r\n",
    "    for i in vector:\r\n",
    "        sum_val += i\r\n",
    "    return sum_val\r\n",
    "\r\n",
    "def sum_square_list_comprehension(vector):\r\n",
    "\r\n",
    "    return sum([i*i for i in vector])\r\n",
    "\r\n",
    "def sum_square_array(vector):\r\n",
    "    sum_val = 0\r\n",
    "    for i in vector:\r\n",
    "        sum_val += i\r\n",
    "    return sum_val\r\n",
    "\r\n",
    "def sum_square_numpy(vector):\r\n",
    "    return np.sum(vector*vector)\r\n",
    "\r\n",
    "def sum_square_np_vectorized(vector):\r\n",
    "    return np.dot(vector, vector)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "vector = [i for i in range(1_000_000)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "%%timeit\r\n",
    "sum_square_lists(vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29.8 ms ± 995 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "%%timeit\r\n",
    "sum_square_list_comprehension(vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "71.5 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "vector = array('l', range(1_000_000))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "%%timeit\r\n",
    "sum_square_array(vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35.6 ms ± 910 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "vector = np.arange(1_000_000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "%%timeit\r\n",
    "sum_square_numpy(vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8 ms ± 8.31 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "%%timeit\r\n",
    "sum_square_np_vectorized(vector)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "439 µs ± 2.26 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can clearly see numpy based both operations have significant speedups compared to the generic python data stuctures. In the numpy based loop we imply the numpy that each element should multiply by itself, which in turn gives us significant performance.\r\n",
    "\r\n",
    "\r\n",
    "Additionally the vectorized function performs way faster than its equivalent normal function.\r\n",
    "\r\n",
    "With those in mind we can use numpy for our diffusion problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "%%writefile scripts/run_experiment_vectorized.py\r\n",
    "\r\n",
    "import time\r\n",
    "from numpy import roll, zeros\r\n",
    "\r\n",
    "\r\n",
    "def shift_vals(grid):\r\n",
    "\r\n",
    "    return (roll(grid, +1, 0) +  \r\n",
    "            roll(grid, -1, 0) +\r\n",
    "            roll(grid, +1, 1) +\r\n",
    "            roll(grid, -1, 1) -\r\n",
    "            4 * grid )\r\n",
    "\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, dt, D = 1.0):\r\n",
    "    return grid + dt * D * shift_vals(grid)\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "\r\n",
    "    grid = zeros((max_y, max_x))\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    grid[block_low:block_high, block_low:block_high] = 0.005\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        grid = step(grid, 0.1)\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640,640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/run_experiment_vectorized.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Obviously this has less code lines than the previous implementation. So line profiler is not useful. But still we can see the overall performance as below.\r\n",
    "\r\n",
    "<center><image src=\"./img/10.jpg\" width=\"800\"/></center>\r\n",
    "\r\n",
    "The total time for 150 iterations is less than 2 seconds!\r\n",
    "\r\n",
    "Above happens for many reasons. Mainly numpy arrays are specialized and does not support all the python list functionalities. They are expecting a single data type (in our case integer) unlike python list which can accept any value. Also as mentioned they keep values not references and store them in contigues manner. And also supports CPU level vectorization instructions. All those combined provide massive performance in applicable scenarios.\r\n",
    "\r\n",
    "But above can be further optimized. In previous implementation, in each step new array is getting allocated to store the data after rolling. This is time consuming task in a CPU bound work. Therefore we can reduce that time by first defining a memory space and reusing it for further calculations (in this case it is possible). To do that we need to understand how numpy memory allocation happens in certain scenarios."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "array1 = np.random.random((10,10))\r\n",
    "array2 = np.random.random((10,10))\r\n",
    "print(id(array1))\r\n",
    "print(id(array2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2412461656176\n",
      "2412388653552\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "array1 = array1 + array2\r\n",
    "print(id(array1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2412388654128\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "array1 = np.random.random((10,10))\r\n",
    "array2 = np.random.random((10,10))\r\n",
    "print(id(array1))\r\n",
    "print(id(array2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2412393274608\n",
      "2412388654128\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "array1 += array2\r\n",
    "print(id(array1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2412393274608\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see in the first method, after the addition operation, array1 id has changed which indicate the memory address change.\r\n",
    "\r\n",
    "But on the other hand, in second addition method array1 id does not change. Which means it does the addition in place. Therefore by using this method, we can reduce memory allocations of our programs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 100, 100))\r\n",
    "array1 = array1 + array2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.89 µs ± 65.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "%%timeit array1, array2 = np.random.random((2, 100, 100))\r\n",
    "array1 += array2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.82 µs ± 39.4 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "%%writefile scripts/run_experiment_mem_optimized.py\r\n",
    "\r\n",
    "import time\r\n",
    "from numpy import roll, zeros, copyto\r\n",
    "\r\n",
    "\r\n",
    "def shift_vals(grid, next_grid):\r\n",
    "    copyto(next_grid, grid)\r\n",
    "    next_grid +=  roll(grid, +1, 0)\r\n",
    "    next_grid +=  roll(grid, -1, 0)\r\n",
    "    next_grid +=  roll(grid, +1, 1)\r\n",
    "    next_grid +=  roll(grid, -1, 1)\r\n",
    "    next_grid *= -4\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, next_grid, dt, D = 1.0):\r\n",
    "    shift_vals(grid, next_grid)\r\n",
    "    next_grid *= dt * D\r\n",
    "    grid += next_grid\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "    grid = zeros((max_y, max_x))\r\n",
    "    next_grid = zeros((max_y, max_x))\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    grid[block_low:block_high, block_low:block_high] = 0.005\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        step(grid, next_grid, 0.1)\r\n",
    "        grid, next_grid = next_grid, grid # Inplace variable swap\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640,640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/run_experiment_mem_optimized.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> It is important to remember that since we want each operation to be in-place, whenever we do a vector operation, we must put it on its own line. This can make something as simple as A = A * B + C become quite convoluted.\r\n",
    "\r\n",
    "The time analysis of above script is as follows.\r\n",
    "\r\n",
    "<center><image src=\"./img/11.jpg\" width=\"700\"/></center>\r\n",
    "\r\n",
    "If we inspect the time taken by the above memory optimized version, it performs considerably better than the just vectorized version. This is mainly due to less memory allocation/change during the execution.\r\n",
    "\r\n",
    "Also we can see that majority of the time consumed by our program goes to shift_vals() function. This is due to memory operations of numpy roll function. Therefore we can optimize that by using a more specialized version for our usecase. But this comes with additional programming complexity and readability problems. So it is important to do such things carefully validating the pros and cons."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "%%writefile scripts/run_experiment_further_mem_optimized.py\r\n",
    "\r\n",
    "import time\r\n",
    "from numpy import roll, zeros, copyto, asarray, all\r\n",
    "\r\n",
    "def shift_sum_optimized(grid, shift_val, axis, next_grid):\r\n",
    "    '''\r\n",
    "    This is faster because this does the addition along with the numpy fast indexing operations.\r\n",
    "    Therefore we dont need to do the addition operations separately.\r\n",
    "    \r\n",
    "    '''\r\n",
    "    if(axis==0):\r\n",
    "        next_grid[shift_val:,:] += grid[:-shift_val,:]\r\n",
    "        next_grid[:shift_val,:] += grid[-shift_val:,:]\r\n",
    "    elif(axis==1):\r\n",
    "        next_grid[:,shift_val:] += grid[:,:-shift_val]\r\n",
    "        next_grid[:,:shift_val] += grid[:,-shift_val:]\r\n",
    "\r\n",
    "def test_shift_sum_optimized():\r\n",
    "    rollee = asarray([[1, 2], [3, 4]])\r\n",
    "    for shift in (+1, -1):\r\n",
    "        for axis in (0, 1):\r\n",
    "            out = asarray([[6, 3], [9, 2]])\r\n",
    "\r\n",
    "            expected_result = roll(rollee, shift, axis=axis) + out\r\n",
    "            shift_sum_optimized(rollee, shift, axis, out)\r\n",
    "\r\n",
    "            assert all(expected_result == out)\r\n",
    "\r\n",
    "def shift_vals(grid, next_grid):\r\n",
    "    copyto(next_grid, grid)\r\n",
    "    shift_sum_optimized(grid, +1, 0, next_grid)\r\n",
    "    shift_sum_optimized(grid, -1, 0, next_grid)\r\n",
    "    shift_sum_optimized(grid, +1, 1, next_grid)\r\n",
    "    shift_sum_optimized(grid, -1, 1, next_grid)\r\n",
    "    next_grid *= -4\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, next_grid, dt, D = 1.0):\r\n",
    "    shift_vals(grid, next_grid)\r\n",
    "    next_grid *= dt * D\r\n",
    "    grid += next_grid\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "    grid = zeros((max_y, max_x))\r\n",
    "    next_grid = zeros((max_y, max_x))\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    grid[block_low:block_high, block_low:block_high] = 0.005\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        step(grid, next_grid, 0.1)\r\n",
    "        grid, next_grid = next_grid, grid # Inplace variable swap\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "            \r\n",
    "test_shift_sum_optimized()\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640,640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting scripts/run_experiment_further_mem_optimized.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time consumption is as follows for the above further improved version.\r\n",
    "\r\n",
    "<center><image src=\"./img/12.jpg\" width=\"700\"/></center>\r\n",
    "\r\n",
    "We can see that execution time has been reduced further compared to the previous implementation.\r\n",
    "\r\n",
    "One annoyance we encounter when doing in-place operations using numpy is that we need to separate the operations explicitly or they will create temporary variables in the middle (eg:- A * B + C). \r\n",
    "\r\n",
    "To help in such situations there are many modules. `numexpr` is one such module which can take a vector expression and compile it to a efficient code optimized for low cache misses and low temporary space usages. Sample usage of numexpr package is shown below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "%%writefile scripts/run_experiment_numexpr_optimized.py\r\n",
    "\r\n",
    "import time\r\n",
    "from numpy import roll, zeros, copyto, asarray, all\r\n",
    "from numexpr import evaluate\r\n",
    "\r\n",
    "def shift_sum_optimized(grid, shift_val, axis, next_grid):\r\n",
    "    '''\r\n",
    "    This is faster because this does the addition along with the numpy fast indexing operations.\r\n",
    "    Therefore we dont need to do the addition operations separately.\r\n",
    "    \r\n",
    "    '''\r\n",
    "    if(axis==0):\r\n",
    "        next_grid[shift_val:,:] += grid[:-shift_val,:]\r\n",
    "        next_grid[:shift_val,:] += grid[-shift_val:,:]\r\n",
    "    elif(axis==1):\r\n",
    "        next_grid[:,shift_val:] += grid[:,:-shift_val]\r\n",
    "        next_grid[:,:shift_val] += grid[:,-shift_val:]\r\n",
    "\r\n",
    "def test_shift_sum_optimized():\r\n",
    "    rollee = asarray([[1, 2], [3, 4]])\r\n",
    "    for shift in (+1, -1):\r\n",
    "        for axis in (0, 1):\r\n",
    "            out = asarray([[6, 3], [9, 2]])\r\n",
    "\r\n",
    "            expected_result = roll(rollee, shift, axis=axis) + out\r\n",
    "            shift_sum_optimized(rollee, shift, axis, out)\r\n",
    "\r\n",
    "            assert all(expected_result == out)\r\n",
    "\r\n",
    "def shift_vals(grid, next_grid):\r\n",
    "    copyto(next_grid, grid)\r\n",
    "    shift_sum_optimized(grid, +1, 0, next_grid)\r\n",
    "    shift_sum_optimized(grid, -1, 0, next_grid)\r\n",
    "    shift_sum_optimized(grid, +1, 1, next_grid)\r\n",
    "    shift_sum_optimized(grid, -1, 1, next_grid)\r\n",
    "    next_grid *= -4\r\n",
    "\r\n",
    "@profile\r\n",
    "def step(grid, next_grid, dt, D = 1.0):\r\n",
    "    shift_vals(grid, next_grid)\r\n",
    "    evaluate(\"next_grid * D * dt + grid\", out=next_grid)\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(num_iterations, grid_shape):\r\n",
    "\r\n",
    "    # Initial grid\r\n",
    "    max_y, max_x = grid_shape\r\n",
    "    grid = zeros((max_y, max_x))\r\n",
    "    next_grid = zeros((max_y, max_x))\r\n",
    "\r\n",
    "    # Simulating a drop of dye in the middle of our simulated region\r\n",
    "    block_low = int(grid_shape[0] * 0.4)\r\n",
    "    block_high = int(grid_shape[0] * 0.5)\r\n",
    "\r\n",
    "    grid[block_low:block_high, block_low:block_high] = 0.005\r\n",
    "\r\n",
    "    # Running the experiment\r\n",
    "    st = time.time()\r\n",
    "    for _ in range(num_iterations):\r\n",
    "        step(grid, next_grid, 0.1)\r\n",
    "        grid, next_grid = next_grid, grid # Inplace variable swap\r\n",
    "\r\n",
    "    return time.time() - st\r\n",
    "            \r\n",
    "test_shift_sum_optimized()\r\n",
    "\r\n",
    "if __name__== '__main__':\r\n",
    "    run_experiment(150, (640,640))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing scripts/run_experiment_numexpr_optimized.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Important thing to note in using this module is that, it is optimized for caching. Therefore if the program is small enough to fit in the cache then there is no point using this. Also compiling the vector operations specifically add a considerable overhead to the program. To get a noticable performance improvement we need to have large enough program complexity."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "Other than numpy, `pandas` library is also very popular in python world for data manipulation tasks. Its table like data structure (data frame) performs operations eagerly to the data columns and often generate intermediate arrays while doing the operation. Therefore it is generally recommended to expect three to five times memory usage than the actual data while manipulating dataframes. Typically pandas works well for datasets up to 10GB assuming the computer have enough memory. Following are few tips that we might want to focus in pandas.\r\n",
    "\r\n",
    "1. Pandas uses numpy data types mainly. But for additional features it has its own data types. Depending on the situation we might want to choose correct ones. (for example if our integer dataset contains NaN values data type would be `Int64` rather than `int64` (note the capitalization of data type name))\r\n",
    "2. Try to use `apply` function rather than iterrows or iloc methods to improve performance.\r\n",
    "3. Pandas `concat` function creates entirely new dataframe/ series upon its use. Therefore should avoid repeated calls as much as possible.\r\n",
    "4. Install the optional dependencies `numexpr` and `bottleneck` for additional performance improvements.\r\n",
    "5. For categorical type data, use `categorical` datatype in pandas for improved speed in calculations.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('High_Performance_Concepts_in_Python-45__Ubn2': virtualenv)"
  },
  "interpreter": {
   "hash": "7e345707fd4776d029d2a8a839d91a2c00b4b8e78ea36281d84f354477ba90d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}