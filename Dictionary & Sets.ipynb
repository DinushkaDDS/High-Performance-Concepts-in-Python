{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Dictionary and Sets - Properties**\r\n",
    "\r\n",
    "Dictionaries and Sets are great to hold data which dont have a inherent order and unique. Another important characteristic is they should be hashable. Due to this hashable property we are able to access/search items in a list with O(1) time complexity. Also their insertion time is O(1)(depends on the hash function).\r\n",
    "\r\n",
    "But those compelling properties comes with a cost like additional memory footprint, additional complexiy/time cost for other operations etc.\r\n",
    "\r\n",
    "Dictionaries and sets work using hash functions and tables. There we first define a memory area and using the Hash function we identify where we need to put the element(index). (Knowledge about hash collisions and all the other craps related to hasp maps will be needed!)\r\n",
    "\r\n",
    "\r\n",
    "But basically what happens is when we try to insert a value to dictionary, first we calculate the hash and then we mask it. This effectively turn the hash value (very large value) to a index in an array (or put the value in to one of the predefined buckets)\r\n",
    "\r\n",
    "* eg:- \r\n",
    "    - hash value = 28794\r\n",
    "    - num of buckets = 8\r\n",
    "    - then index = 28794 & 0b111 = 2 so the second index.\r\n",
    "\r\n",
    "The mask value of this case is 0b111 since we only have 8 memoy blocks. But if we have more then we need to make the mask resized as well.\r\n",
    "\r\n",
    "Then we need to check the bucket/index is already in use. If thats the case we can check the current value with existing value. If they are same, then no issue. Else we need to find a new place to add.\r\n",
    "\r\n",
    "> Apparently in python instead of storing values in predefined buckets it saves item index in a array. Then use it to access the actual data in the memory. This is a optimization used by python. Because of this property in python dictionary we can keep track of in which order items were added!\r\n",
    "\r\n",
    "To find a new index in case of hash collision, python uses a linear function `probing`. Here we use another mask using the item's higher order hash values. Psuedo implementation is as followed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def index_sequence(key, mask=0b111, collision_shift=5):\r\n",
    "    hash_val = hash(key) # This returns a integer.\r\n",
    "    i = hash_val & mask\r\n",
    "    yield i\r\n",
    "\r\n",
    "    # If theres a collision this part will help. (very cleaver IMO!)\r\n",
    "    while True:\r\n",
    "        hash_val >>= collision_shift\r\n",
    "        i = (i * 5 + hash_val + 1) & mask\r\n",
    "        yield i"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> The while(True) in the code helps to avoid continuous hash collisions for hash values which have same bits for corresponding mask part bits. Also when defining a hash function for data types it is important to design them to reduce hash collisions as much as possible.\r\n",
    "\r\n",
    "We do the exact same thing as above for lookups as well.\r\n",
    "\r\n",
    "But when it comes to deletions things are bit different. We cant simply mark the deleted item location as null. In insertion process we check for null values to solve hash collisions. Therefore we need to make sure deletion does not affect that. To do that we write a special value to mark the deleted item.\r\n",
    "\r\n",
    "In python, dictionary, hash table must be dynamically resized to accomadate to the new items. This is an expensive process as all the already existing elements need to be reinserted with new mask values. Since this does not happen often still the amortized time complexity is considered as O(1). Expanding algorithm is as follows.\r\n",
    "\r\n",
    "Always start with 8 slots.\r\n",
    "If 2/3 slots are full, then size need to be increased by 3 times.\r\n",
    "\r\n",
    "    eg:- after the sixth element, memory slots will get increased to 18. From there once 13th item inserted slots will be increased to 39 etc.\r\n",
    "(Also resizing can happen to reduce size as well)\r\n",
    "\r\n",
    "\r\n",
    "> In python if we need to make a custom class hashable, we can either use default hash which is the memory location id. Or we can define a custom __hash__ function with custom __eq__ function so that comparisons can be made.\r\n",
    "\r\n",
    "</br>\r\n",
    "\r\n",
    "> Also it important to define the hash function to return evenly distributed values. This property ensures the minimum number of collisions between items.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import string\r\n",
    "import timeit\r\n",
    "\r\n",
    "\r\n",
    "class BadHash(str):\r\n",
    "\r\n",
    "    def __hash__(self) -> int:\r\n",
    "        return 42\r\n",
    "\r\n",
    "class GoodHash(str):\r\n",
    "\r\n",
    "    def __hash__(self) -> int:\r\n",
    "        a_ord = ord('a')\r\n",
    "        return (ord(self[1]) - a_ord)+(ord(self[0]) - a_ord)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "good_dict = set()\r\n",
    "bad_dict = set()\r\n",
    "\r\n",
    "\r\n",
    "for let1 in string.ascii_lowercase:\r\n",
    "    for let2 in string.ascii_lowercase:\r\n",
    "        key = let1+let2\r\n",
    "\r\n",
    "        good_dict.add(GoodHash(key))\r\n",
    "        bad_dict.add(BadHash(key))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "%timeit GoodHash('zz') in good_dict"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "354 ns ± 2.6 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%timeit BadHash('zz') in bad_dict"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.8 µs ± 147 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the effect of having good and bad hashing function using above examples. Below is the same experiment but with different timeit module usage pattern."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "timeit.repeat(\r\n",
    "\"key in bad_dict\",\r\n",
    " '''from __main__ import bad_dict, BadHash\r\n",
    "key = BadHash('zz')''',\r\n",
    " repeat=3, \r\n",
    " number=1_000_000)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10.612844799999948, 10.61202030000004, 10.67579749999959]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "timeit.repeat(\r\n",
    "\"key in good_dict\",\r\n",
    " '''from __main__ import good_dict, GoodHash\r\n",
    "key = GoodHash('zz')''',\r\n",
    " repeat=3, \r\n",
    " number=1_000_000)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.21189019999974334, 0.20485240000016347, 0.21517530000028273]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another Fact about python is the way it looks for variables in names spaces. \r\n",
    "It normally flows like below\r\n",
    "\r\n",
    "1. locals() array - stores local variables\r\n",
    "2. globals() dictionary - stores global level variables\r\n",
    "3. \\_\\_builtin\\_\\_ object - technically module object which stores module level values. (here we check its locals() map for our required value)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import math\r\n",
    "from math import sin\r\n",
    "\r\n",
    "\r\n",
    "def test1(x):\r\n",
    "    res = 1\r\n",
    "    for _ in range(1000):\r\n",
    "        res+= math.sin(x)  #Accesing the function from module level __builtin__ object\r\n",
    "    return res\r\n",
    "\r\n",
    "def test2(x):\r\n",
    "    res = 1\r\n",
    "    for _ in range(1000):\r\n",
    "        res+= sin(x)  # Function is already loaded from module, and now in globals().\r\n",
    "    return res\r\n",
    "\r\n",
    "def test3(x, func=math.sin):\r\n",
    "    res = 1\r\n",
    "    for _ in range(1000):\r\n",
    "        res+= func(x)  # accessing the function as a local variable.\r\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "%timeit test1(90)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "115 µs ± 307 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "%timeit test2(90)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100 µs ± 450 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "%timeit test3(90)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "94.4 µs ± 575 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import dis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "dis.dis(test1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  6           0 LOAD_CONST               1 (1)\n",
      "              2 STORE_FAST               1 (res)\n",
      "\n",
      "  7           4 LOAD_GLOBAL              0 (range)\n",
      "              6 LOAD_CONST               2 (1000)\n",
      "              8 CALL_FUNCTION            1\n",
      "             10 GET_ITER\n",
      "        >>   12 FOR_ITER                18 (to 32)\n",
      "             14 STORE_FAST               2 (_)\n",
      "\n",
      "  8          16 LOAD_FAST                1 (res)\n",
      "             18 LOAD_GLOBAL              1 (math)\n",
      "             20 LOAD_METHOD              2 (sin)\n",
      "             22 LOAD_FAST                0 (x)\n",
      "             24 CALL_METHOD              1\n",
      "             26 INPLACE_ADD\n",
      "             28 STORE_FAST               1 (res)\n",
      "             30 JUMP_ABSOLUTE           12\n",
      "\n",
      "  9     >>   32 LOAD_FAST                1 (res)\n",
      "             34 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dis.dis(test2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 12           0 LOAD_CONST               1 (1)\n",
      "              2 STORE_FAST               1 (res)\n",
      "\n",
      " 13           4 LOAD_GLOBAL              0 (range)\n",
      "              6 LOAD_CONST               2 (1000)\n",
      "              8 CALL_FUNCTION            1\n",
      "             10 GET_ITER\n",
      "        >>   12 FOR_ITER                16 (to 30)\n",
      "             14 STORE_FAST               2 (_)\n",
      "\n",
      " 14          16 LOAD_FAST                1 (res)\n",
      "             18 LOAD_GLOBAL              1 (sin)\n",
      "             20 LOAD_FAST                0 (x)\n",
      "             22 CALL_FUNCTION            1\n",
      "             24 INPLACE_ADD\n",
      "             26 STORE_FAST               1 (res)\n",
      "             28 JUMP_ABSOLUTE           12\n",
      "\n",
      " 15     >>   30 LOAD_FAST                1 (res)\n",
      "             32 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "dis.dis(test3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 18           0 LOAD_CONST               1 (1)\n",
      "              2 STORE_FAST               2 (res)\n",
      "\n",
      " 19           4 LOAD_GLOBAL              0 (range)\n",
      "              6 LOAD_CONST               2 (1000)\n",
      "              8 CALL_FUNCTION            1\n",
      "             10 GET_ITER\n",
      "        >>   12 FOR_ITER                16 (to 30)\n",
      "             14 STORE_FAST               3 (_)\n",
      "\n",
      " 20          16 LOAD_FAST                2 (res)\n",
      "             18 LOAD_FAST                1 (func)\n",
      "             20 LOAD_FAST                0 (x)\n",
      "             22 CALL_FUNCTION            1\n",
      "             24 INPLACE_ADD\n",
      "             26 STORE_FAST               2 (res)\n",
      "             28 JUMP_ABSOLUTE           12\n",
      "\n",
      " 21     >>   30 LOAD_FAST                2 (res)\n",
      "             32 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see 3 functions have different access patterns to the `sin` function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('High_Performance_Concepts_in_Python-45__Ubn2': virtualenv)"
  },
  "interpreter": {
   "hash": "7e345707fd4776d029d2a8a839d91a2c00b4b8e78ea36281d84f354477ba90d2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}