{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Why Profiling is needed?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Profiling is important to understand which parts of program consume most of the resources. This helps to improve the slow executing code segments to perform better or to focus on finding alternatives. Not only CPU, but also memory(RAM), disk usage(Disk I/O), network operations etc. also can be measured to determine bottlenecks of a program."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basic method of identifying the bottlenecks is understanding the time consumption of the program sections. In jupyter notebook we can use `%%timeit` magic, time.time() or time decorators. In order to test the mentioned techniques we will define a special function named `Julia Set` which is Heavy CPU bound and less memory consuming non linear time consuming task. More technically speaking this is a fractal function which generates a complex output image.\r\n",
    "\r\n",
    "\r\n",
    "<center><image src=\"./img/1.jpg\" width=\"200px\" /></center>\r\n",
    "\r\n",
    "The basic psuedo code for calculation is as follows. In here coordinates are imaginary numbers and max_iter is a predefined variable for the function.\r\n",
    "<pre style='color:yellow'> \r\n",
    "coordinates = []\r\n",
    "\r\n",
    "for z in coordinates:\r\n",
    "    for _ in range(max_iter):\r\n",
    "        \r\n",
    "        if (abs(z)< thres):\r\n",
    "            z = z*z + c\r\n",
    "        else:\r\n",
    "            break\r\n",
    "</pre>\r\n",
    "\r\n",
    "But for the sake of testing various scenarios following imlpementation has few other parts added to it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import time\r\n",
    "import cv2\r\n",
    "\r\n",
    "# area of imaginary space to calculate pixel values\r\n",
    "x1, x2, y1, y2 = -1.8, 1.8, -1.8, 1.8\r\n",
    "c_real, c_img = -0.62772, -.42193"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def display_img(arr):\r\n",
    "    '''\r\n",
    "    Function to display the generated output as an image.\r\n",
    "    '''\r\n",
    "    import numpy as np\r\n",
    "    arr = np.array(arr)\r\n",
    "    arr = arr.reshape((int(len(arr)**0.5), int(len(arr)**0.5)), order='C')\r\n",
    "\r\n",
    "    arr = np.array(arr, dtype=np.uint8)\r\n",
    "    cv2.imshow(\"Julia set\", arr)\r\n",
    "    cv2.waitKey(0)\r\n",
    "    cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def calculate_juliaset_serial(maxiter, zs, cs):\r\n",
    "    \"\"\"Calculate output list using Julia update rule\"\"\"\r\n",
    "    output = [0] * len(zs)\r\n",
    "    for i in range(len(zs)):\r\n",
    "        n = 0\r\n",
    "        z = zs[i]\r\n",
    "        c = cs[i]\r\n",
    "        while abs(z) < 2 and n < maxiter:\r\n",
    "            z = z * z + c\r\n",
    "            n += 1\r\n",
    "        output[i] = n\r\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def calc_juliaset_time(desired_width, max_iterations):\r\n",
    "    \"\"\"Create a list of complex coordinates (zs) and complex parameters (cs), to build Julia set\"\"\"\r\n",
    "\r\n",
    "    x_step = (x2 - x1) / desired_width\r\n",
    "    y_step = (y1 - y2) / desired_width\r\n",
    "\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "\r\n",
    "    ycoord = y2\r\n",
    "    while ycoord > y1:\r\n",
    "        y.append(ycoord)\r\n",
    "        ycoord += y_step\r\n",
    "    \r\n",
    "    xcoord = x1\r\n",
    "    while xcoord < x2:\r\n",
    "        x.append(xcoord)\r\n",
    "        xcoord += x_step\r\n",
    "\r\n",
    "    zs = []\r\n",
    "    cs = []\r\n",
    "    for ycoord in y:\r\n",
    "        for xcoord in x:\r\n",
    "            zs.append(complex(xcoord, ycoord))\r\n",
    "            cs.append(complex(c_real, c_img))\r\n",
    "    \r\n",
    "    print(\"Length of x:\", len(x))\r\n",
    "    print(\"Total elements:\", len(zs))\r\n",
    "\r\n",
    "    start_time = time.time()\r\n",
    "    output = calculate_juliaset_serial(max_iterations, zs, cs)\r\n",
    "    end_time = time.time()\r\n",
    "\r\n",
    "    secs = end_time - start_time\r\n",
    "    print(calculate_juliaset_serial.__name__ + \" took\", secs, \"seconds\")\r\n",
    "\r\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# reasonable defaults for a laptop\r\n",
    "val = calc_juliaset_time(desired_width=1000, max_iterations=300)\r\n",
    "display_img(val)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of x: 1000\n",
      "Total elements: 1000000\n",
      "calculate_juliaset_serial took 6.378915786743164 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As above we can use the julia set to as a baseline task to check the performance. In the above case we have used the good old print statement with time difference to measure the performance. But this time change with the other processes running in the computer. Also print statements like above causes inconvienience in the long run. Instead we can use a decorator to measure time and print. (Or in Jupyter notebooks magic functions :D )"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from functools import wraps\r\n",
    "\r\n",
    "def timefn(fn):\r\n",
    "\r\n",
    "    @wraps(fn)\r\n",
    "    def measure_time(*args, **kwargs):\r\n",
    "\r\n",
    "        t1 = time.time()\r\n",
    "        result = fn(*args, **kwargs)\r\n",
    "        t2 = time.time()\r\n",
    "\r\n",
    "        print(f\"@timefn: {fn.__name__} took {t2 - t1} seconds\")\r\n",
    "        return result\r\n",
    "    \r\n",
    "    return measure_time\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "@timefn\r\n",
    "def calc_juliaset_time(desired_width, max_iterations):\r\n",
    "    \"\"\"Create a list of complex coordinates (zs) and complex parameters (cs), to build Julia set\"\"\"\r\n",
    "\r\n",
    "    x_step = (x2 - x1) / desired_width\r\n",
    "    y_step = (y1 - y2) / desired_width\r\n",
    "\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "\r\n",
    "    ycoord = y2\r\n",
    "    while ycoord > y1:\r\n",
    "        y.append(ycoord)\r\n",
    "        ycoord += y_step\r\n",
    "    \r\n",
    "    xcoord = x1\r\n",
    "    while xcoord < x2:\r\n",
    "        x.append(xcoord)\r\n",
    "        xcoord += x_step\r\n",
    "\r\n",
    "    zs = []\r\n",
    "    cs = []\r\n",
    "    for ycoord in y:\r\n",
    "        for xcoord in x:\r\n",
    "            zs.append(complex(xcoord, ycoord))\r\n",
    "            cs.append(complex(c_real, c_img))\r\n",
    "    \r\n",
    "    print(\"Length of x:\", len(x))\r\n",
    "    print(\"Total elements:\", len(zs))\r\n",
    "\r\n",
    "    output = calculate_juliaset_serial(max_iterations, zs, cs)\r\n",
    "\r\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "x = calc_juliaset_time(1000, 300)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of x: 1000\n",
      "Total elements: 1000000\n",
      "@timefn: calc_juliaset_time took 6.546191453933716 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other than above methods, we can use python provided `timeit` function. It provides more functionality to time a execution with repetitions and loops.\r\n",
    "\r\n",
    "Also it is important to keep track of other computer processes, because sometimes those may cause sudden spikes in CPU usage which may affect our profiling process.\r\n",
    "\r\n",
    "Outside of python, we can use OS provided functionalities such as UNIX `time` command to measure program execution time as well.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "__time --verbose python_script_name.py__\r\n",
    "\r\n",
    "</center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another way to do the profiling is using the `cProfile` or `Profile` modules provided in the standard library.\r\n",
    "\r\n",
    "<center>Eg:-\r\n",
    "\r\n",
    "__python -m cProfile -s cumulative python_script_name.py__\r\n",
    "\r\n",
    "</center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a example execution of cProfile on juliaset calculation script. As we can see it measures the execution times, number of calls to each function with little bit of overhead to the cProfiler itself. This is a comparatively descriptive way of analyzing our code to identify bottlenecks.\r\n",
    "\r\n",
    "<center><image src=\"./img/2.jpg\" width=\"500px\" /></center>\r\n",
    "\r\n",
    "A point to note is that cProfile gives details on funcion call basis, not line basis. So it would be bit harder to pinpoint problematic location of the code.\r\n",
    "\r\n",
    "Also we can write the cProfile output to a statistics file which can later be read by python itself. This way we can further analyze the details regarding our program.\r\n",
    "\r\n",
    "<center>Eg:-\r\n",
    "\r\n",
    "__python -m cProfile -o profile.stats python_script_name.py__\r\n",
    "\r\n",
    "</center>\r\n",
    "\r\n",
    "Above command will write a file named profile.stats and we can use it as below in python."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pstats\r\n",
    "\r\n",
    "p = pstats.Stats('scripts/profile.stats')\r\n",
    "p.sort_stats('cumulative')\r\n",
    "p.print_stats()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Apr 29 12:13:13 2022    scripts/profile.stats\n",
      "\n",
      "         36221991 function calls in 10.417 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   10.417   10.417 {built-in method builtins.exec}\n",
      "        1    0.020    0.020   10.417   10.417 juliset.py:2(<module>)\n",
      "        1    0.405    0.405   10.396   10.396 juliset.py:18(calc_juliaset_time)\n",
      "        1    6.102    6.102    9.842    9.842 juliset.py:5(calculate_juliaset_serial)\n",
      " 34219980    3.740    0.000    3.740    0.000 {built-in method builtins.abs}\n",
      "  2002000    0.149    0.000    0.149    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x27e71f64e20>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "p.print_callers()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Ordered by: cumulative time\n",
      "\n",
      "Function                                          was called by...\n",
      "                                                      ncalls  tottime  cumtime\n",
      "{built-in method builtins.exec}                   <- \n",
      "juliset.py:2(<module>)                            <-       1    0.020   10.417  {built-in method builtins.exec}\n",
      "juliset.py:18(calc_juliaset_time)                 <-       1    0.405   10.396  juliset.py:2(<module>)\n",
      "juliset.py:5(calculate_juliaset_serial)           <-       1    6.102    9.842  juliset.py:18(calc_juliaset_time)\n",
      "{built-in method builtins.abs}                    <- 34219980    3.740    3.740  juliset.py:5(calculate_juliaset_serial)\n",
      "{method 'append' of 'list' objects}               <- 2002000    0.149    0.149  juliset.py:18(calc_juliaset_time)\n",
      "{built-in method builtins.print}                  <-       2    0.000    0.000  juliset.py:18(calc_juliaset_time)\n",
      "{built-in method builtins.len}                    <-       2    0.000    0.000  juliset.py:5(calculate_juliaset_serial)\n",
      "                                                           2    0.000    0.000  juliset.py:18(calc_juliaset_time)\n",
      "{method 'disable' of '_lsprof.Profiler' objects}  <- \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x27e71f64e20>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Line Profiler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the other strong tool to identify CPU bound problems is `Line-Profiler`. (pip install line_profiler). In using this tool, following values are used.\r\n",
    "\r\n",
    "- @profile decorator is used to mark the function need to profile.\r\n",
    "- kernprof script is used to execute the code.\r\n",
    "- '-l' for line by line profiling\r\n",
    "- '-v' for verbose output, if we dont use this argument we will get  an .lprof file as an output which we can analyze later.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "**kernprof -l -v python_script_name.py**\r\n",
    "</center>\r\n",
    "\r\n",
    "\r\n",
    "<center><image src=\"./img/3.jpg\" width=\"700px\" /></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Points to note is that, this profile takes substantial amount of time to run. \r\n",
    "\r\n",
    "Also this reflects interesting insights related to the code we are checking. For example in the above code the line that takes the most amount of time is the while clause, rather than the multiplication part. Even __n ++1__ takes 27% of the total time. (This is apparantly due to the python language dynamic type feature. We will check later.) As for the while loop in order to identify which parts takes the most time lets break it down and analyze again.\r\n",
    "\r\n",
    "<center><image src=\"./img/4.jpg\" width=\"700px\" /></center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assume the below hypothesis.\r\n",
    "\r\n",
    "`Since python statements execute from left to right and opportunistic, it can be helpful to improve performance if we put chepest test(execution wise) to the left.`\r\n",
    "\r\n",
    "If we test this hypothesis we will see that, program does not provide any significant evidence to support that. Which means order of logic test in a statement does not guarantee any reliable performance improvement."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Memory Profiler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just as we can use line profiler to check the execution bottlenecks, we can use memory profilers to check the memory usage of out programs to improve the performance. To do that we can use the python package `memory_profiler`.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "**pip install memory_profiler**\r\n",
    "\r\n",
    "**pip install psutil (to improve profiling speed)**\r\n",
    "</center>\r\n",
    "\r\n",
    "It should be noted that memory profiling is significantly slower than the all previously mentioned techniques. Therefore, it makes sense to run the profiling on a small code part.\r\n",
    "\r\n",
    "To use the memory profiler use below command. This outputs line by line statistics of memory usage of the script we are analyzing.\r\n",
    "<center>\r\n",
    "\r\n",
    "**python -m memory_profiler script_name.py**\r\n",
    "</center>\r\n",
    "\r\n",
    "Also we can use below command to get memory use as samples over time. The output of that command can be used to visualize the memory usage as a plot.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "**mprof run python script.py**\r\n",
    "\r\n",
    "To use the output --> **mprof plot**\r\n",
    "\r\n",
    "To use the memprofiler in Jupyter notebooks first run **%load_ext memory_profiler**\r\n",
    "</center>\r\n",
    "</br>\r\n",
    "\r\n",
    "<center><image src=\"./img/5.png\" width=\"700px\"/></center>\r\n",
    "\r\n",
    "This graph is not accurate due to a problem of my machine at the time!\r\n",
    "\r\n",
    "</br>\r\n",
    "To add more sense to the above plot, we can use labels inside of the code like below. Check the context manager part(with clause part).\r\n",
    "\r\n",
    "<pre style='color:yellow'>\r\n",
    "@profile\r\n",
    "def calculate_z_serial_purepython(maxiter, zs, cs):\r\n",
    "    \"\"\"Calculate output list using Julia update rule\"\"\"\r\n",
    "\r\n",
    "    with profile.timestamp(\"create_output_list\"):\r\n",
    "        output = [0] * len(zs)\r\n",
    "\r\n",
    "    time.sleep(1)\r\n",
    "\r\n",
    "    with profile.timestamp(\"calculate_output\"):   \r\n",
    "        for i in range(len(zs)):\r\n",
    "            n = 0\r\n",
    "            z = zs[i]\r\n",
    "            c = cs[i]\r\n",
    "            while n < maxiter and abs(z) < 2:\r\n",
    "                z = z * z + c\r\n",
    "                n += 1\r\n",
    "            output[i] = n\r\n",
    "return output\r\n",
    "</pre>\r\n",
    "\r\n",
    "If we remove the creation of zs and cs list and then add it to the `calculate_juliaset_serial_expanded` function it self, we can reduce the ram usage by almost half. We can verify this by changing the code and plotting the memory usage again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>\r\n",
    "We can use Ipython %memit function to measure the memory usage as well. (just like %timeit)\r\n",
    "</strong>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PySpy\r\n",
    "\r\n",
    "This is another type of memory profiler that we can use to measure the memory usages of python processes. This uniqueness of this profiler is that, this is a sampling type memory profiler. Which means it checks the already running python process and reports it data back to the user.\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "**pip install py-spy**\r\n",
    "</center>\r\n",
    "\r\n",
    "To use this we need to first identify the python process id. Then we need to pass this to the pyspy tool to start profiling."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examine the Bytecode\r\n",
    "\r\n",
    "The `dis` module helps us to analyze the underline bytecode used by the Cpython virtual machine. It will helps us to identify the coding patterns which would run fast compared to the others.\r\n",
    "\r\n",
    "[Simple Explanation about python VM](https://www.tutorialspoint.com/internal-working-of-python)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import dis\r\n",
    "from scripts.lineprofile_julia import *\r\n",
    "\r\n",
    "dis.dis(calc_juliaset_time)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 49           0 LOAD_GLOBAL              0 (x2)\n",
      "              2 LOAD_GLOBAL              1 (x1)\n",
      "              4 BINARY_SUBTRACT\n",
      "              6 LOAD_FAST                0 (desired_width)\n",
      "              8 BINARY_TRUE_DIVIDE\n",
      "             10 STORE_FAST               2 (x_step)\n",
      "\n",
      " 50          12 LOAD_GLOBAL              2 (y1)\n",
      "             14 LOAD_GLOBAL              3 (y2)\n",
      "             16 BINARY_SUBTRACT\n",
      "             18 LOAD_FAST                0 (desired_width)\n",
      "             20 BINARY_TRUE_DIVIDE\n",
      "             22 STORE_FAST               3 (y_step)\n",
      "\n",
      " 52          24 BUILD_LIST               0\n",
      "             26 STORE_FAST               4 (x)\n",
      "\n",
      " 53          28 BUILD_LIST               0\n",
      "             30 STORE_FAST               5 (y)\n",
      "\n",
      " 55          32 LOAD_GLOBAL              3 (y2)\n",
      "             34 STORE_FAST               6 (ycoord)\n",
      "\n",
      " 56     >>   36 LOAD_FAST                6 (ycoord)\n",
      "             38 LOAD_GLOBAL              2 (y1)\n",
      "             40 COMPARE_OP               4 (>)\n",
      "             42 POP_JUMP_IF_FALSE       64\n",
      "\n",
      " 57          44 LOAD_FAST                5 (y)\n",
      "             46 LOAD_METHOD              4 (append)\n",
      "             48 LOAD_FAST                6 (ycoord)\n",
      "             50 CALL_METHOD              1\n",
      "             52 POP_TOP\n",
      "\n",
      " 58          54 LOAD_FAST                6 (ycoord)\n",
      "             56 LOAD_FAST                3 (y_step)\n",
      "             58 INPLACE_ADD\n",
      "             60 STORE_FAST               6 (ycoord)\n",
      "             62 JUMP_ABSOLUTE           36\n",
      "\n",
      " 60     >>   64 LOAD_GLOBAL              1 (x1)\n",
      "             66 STORE_FAST               7 (xcoord)\n",
      "\n",
      " 61     >>   68 LOAD_FAST                7 (xcoord)\n",
      "             70 LOAD_GLOBAL              0 (x2)\n",
      "             72 COMPARE_OP               0 (<)\n",
      "             74 POP_JUMP_IF_FALSE       96\n",
      "\n",
      " 62          76 LOAD_FAST                4 (x)\n",
      "             78 LOAD_METHOD              4 (append)\n",
      "             80 LOAD_FAST                7 (xcoord)\n",
      "             82 CALL_METHOD              1\n",
      "             84 POP_TOP\n",
      "\n",
      " 63          86 LOAD_FAST                7 (xcoord)\n",
      "             88 LOAD_FAST                2 (x_step)\n",
      "             90 INPLACE_ADD\n",
      "             92 STORE_FAST               7 (xcoord)\n",
      "             94 JUMP_ABSOLUTE           68\n",
      "\n",
      " 65     >>   96 BUILD_LIST               0\n",
      "             98 STORE_FAST               8 (zs)\n",
      "\n",
      " 66         100 BUILD_LIST               0\n",
      "            102 STORE_FAST               9 (cs)\n",
      "\n",
      " 67         104 LOAD_FAST                5 (y)\n",
      "            106 GET_ITER\n",
      "        >>  108 FOR_ITER                46 (to 156)\n",
      "            110 STORE_FAST               6 (ycoord)\n",
      "\n",
      " 68         112 LOAD_FAST                4 (x)\n",
      "            114 GET_ITER\n",
      "        >>  116 FOR_ITER                36 (to 154)\n",
      "            118 STORE_FAST               7 (xcoord)\n",
      "\n",
      " 69         120 LOAD_FAST                8 (zs)\n",
      "            122 LOAD_METHOD              4 (append)\n",
      "            124 LOAD_GLOBAL              5 (complex)\n",
      "            126 LOAD_FAST                7 (xcoord)\n",
      "            128 LOAD_FAST                6 (ycoord)\n",
      "            130 CALL_FUNCTION            2\n",
      "            132 CALL_METHOD              1\n",
      "            134 POP_TOP\n",
      "\n",
      " 70         136 LOAD_FAST                9 (cs)\n",
      "            138 LOAD_METHOD              4 (append)\n",
      "            140 LOAD_GLOBAL              5 (complex)\n",
      "            142 LOAD_GLOBAL              6 (c_real)\n",
      "            144 LOAD_GLOBAL              7 (c_img)\n",
      "            146 CALL_FUNCTION            2\n",
      "            148 CALL_METHOD              1\n",
      "            150 POP_TOP\n",
      "            152 JUMP_ABSOLUTE          116\n",
      "        >>  154 JUMP_ABSOLUTE          108\n",
      "\n",
      " 72     >>  156 LOAD_GLOBAL              8 (print)\n",
      "            158 LOAD_CONST               1 ('Length of x:')\n",
      "            160 LOAD_GLOBAL              9 (len)\n",
      "            162 LOAD_FAST                4 (x)\n",
      "            164 CALL_FUNCTION            1\n",
      "            166 CALL_FUNCTION            2\n",
      "            168 POP_TOP\n",
      "\n",
      " 73         170 LOAD_GLOBAL              8 (print)\n",
      "            172 LOAD_CONST               2 ('Total elements:')\n",
      "            174 LOAD_GLOBAL              9 (len)\n",
      "            176 LOAD_FAST                8 (zs)\n",
      "            178 CALL_FUNCTION            1\n",
      "            180 CALL_FUNCTION            2\n",
      "            182 POP_TOP\n",
      "\n",
      " 75         184 LOAD_GLOBAL             10 (calculate_juliaset_serial_expanded)\n",
      "            186 LOAD_FAST                1 (max_iterations)\n",
      "            188 LOAD_FAST                8 (zs)\n",
      "            190 LOAD_FAST                9 (cs)\n",
      "            192 CALL_FUNCTION            3\n",
      "            194 STORE_FAST              10 (output)\n",
      "\n",
      " 77         196 LOAD_FAST               10 (output)\n",
      "            198 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Here First column is the corresponding line of code from original file.\r\n",
    "- In the second column `>>` indicates a jump point from there to another location of the file.\r\n",
    "- Third column is named as Operation address and its related operation name is in the Fourth column.\r\n",
    "- Fifth column contains the parameters (id like) needed for that operation.\r\n",
    "- Sixth column contains the annotations to identify the parameters mentioned in fifth column with the original code.\r\n",
    "\r\n",
    "Identifying which codes generate more overhead or performance/readability  problems is important in modern day software engineering.\r\n",
    "\r\n",
    "for example below 2 function do the same thing. But their coding styles are vastly different."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def fn_expressive(upper=1_000_000):\r\n",
    "    total = 0\r\n",
    "    for n in range(upper):\r\n",
    "        total += n\r\n",
    "    return total\r\n",
    "\r\n",
    "def fn_compressed(upper=1_000_000):\r\n",
    "    return sum(range(upper))\r\n",
    "\r\n",
    "assert fn_expressive() == fn_compressed()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "%timeit fn_expressive()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "34.4 ms ± 478 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "%timeit fn_compressed()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.8 ms ± 370 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the function which use the built in  function is faster compared to the expressive one. The reason can be seen when we check the bytecode."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dis.dis(fn_expressive)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  2           0 LOAD_CONST               1 (0)\n",
      "              2 STORE_FAST               1 (total)\n",
      "\n",
      "  3           4 LOAD_GLOBAL              0 (range)\n",
      "              6 LOAD_FAST                0 (upper)\n",
      "              8 CALL_FUNCTION            1\n",
      "             10 GET_ITER\n",
      "        >>   12 FOR_ITER                12 (to 26)\n",
      "             14 STORE_FAST               2 (n)\n",
      "\n",
      "  4          16 LOAD_FAST                1 (total)\n",
      "             18 LOAD_FAST                2 (n)\n",
      "             20 INPLACE_ADD\n",
      "             22 STORE_FAST               1 (total)\n",
      "             24 JUMP_ABSOLUTE           12\n",
      "\n",
      "  5     >>   26 LOAD_FAST                1 (total)\n",
      "             28 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "dis.dis(fn_compressed)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  8           0 LOAD_GLOBAL              0 (sum)\n",
      "              2 LOAD_GLOBAL              1 (range)\n",
      "              4 LOAD_FAST                0 (upper)\n",
      "              6 CALL_FUNCTION            1\n",
      "              8 CALL_FUNCTION            1\n",
      "             10 RETURN_VALUE\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Obviously first code have 2 variables to maintain, one jump location due to the for loop and its condition which cause the time overhead."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "f1058ac39a4b5cc6a2d664bf07a90cc7a0b869b1d28e3e4a0289bda448411850"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}